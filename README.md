# DAG Airflow pour la Surveillance du COVID-19

**Automatisation de l'acquisition et du traitement des données COVID-19 avec Apache Airflow**

---

## 🏥 **Contexte**

Vous êtes ingénieur data pour Etalab, une branche de l'État française qui développe des outils numériques pour les citoyens. Dans le cadre de la lutte contre la pandémie de COVID-19, vous êtes chargé de construire un pipeline Airflow pour automatiser l'acquisition et le traitement des données COVID-19. Ce pipeline sera utilisé par le gouvernement français pour surveiller l'évolution de la pandémie.

---

## 🎯 **Objectif**

Construire un pipeline simple mais efficace avec Apache Airflow pour :

- **Automatiser l'acquisition des données** : Collecter les données COVID-19 à partir de sources fiables.
- **Traitement des données** : Nettoyer et transformer les données pour les rendre exploitables.
- **Surveillance continue** : Fournir des mises à jour régulières pour aider à la prise de décision.

---

## 🛠️ **Technologies Utilisées**

- **Apache Airflow** : Pour l'orchestration des workflows et l'automatisation des pipelines de données.
- **Python** : Pour le développement des scripts de traitement des données.
- **Pandas** : Pour la manipulation et l'analyse des données.

---

## 📊 **Résultat**

Le pipeline Airflow permet de générer des visualisations et des rapports réguliers sur l'évolution de la pandémie de COVID-19. Voici un exemple de visualisation produite par le pipeline :

![Exemple de Visualisation](https://github.com/user-attachments/assets/17ca92fc-fd8d-429f-bcc0-fefea90382fd)

